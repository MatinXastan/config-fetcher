import os
import requests
import base64
import re
import json
import shutil
from collections import defaultdict
from urllib.parse import unquote, urlparse, parse_qs

# --- Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ú©Ø§Ù…Ù„â€ŒØªØ± Ø¨Ø±Ø§ÛŒ Ù†Ú¯Ø§Ø´Øª Ú©Ø¯Ù‡Ø§ÛŒ Ú©Ø´ÙˆØ± Ø¨Ù‡ Ù†Ø§Ù… Ú©Ø§Ù…Ù„ ---
COUNTRY_ALIASES = {
    "Germany": ["Germany", "Deutschland", "DE", "ğŸ‡©ğŸ‡ª"],
    "USA": ["United States", "USA", "US", "ğŸ‡ºğŸ‡¸"],
    "Netherlands": ["Netherlands", "NL", "ğŸ‡³ğŸ‡±"],
    "France": ["France", "FR", "ğŸ‡«ğŸ‡·"],
    "UK": ["United Kingdom", "UK", "GB", "ğŸ‡¬ğŸ‡§"],
    "Canada": ["Canada", "CA", "ğŸ‡¨ğŸ‡¦"],
    "Japan": ["Japan", "JP", "ğŸ‡¯ğŸ‡µ"],
    "Singapore": ["Singapore", "SG", "ğŸ‡¸ğŸ‡¬"],
    "Finland": ["Finland", "FI", "ğŸ‡«ğŸ‡®"],
    "Iran": ["Iran", "IR", "ğŸ‡®ğŸ‡·"],
    "Turkey": ["Turkey", "TR", "ğŸ‡¹ğŸ‡·"],
    "Russia": ["Russia", "RU", "ğŸ‡·ğŸ‡º"],
    "Austria": ["Austria", "AT", "ğŸ‡¦ğŸ‡¹"],
    "Poland": ["Poland", "PL", "ğŸ‡µğŸ‡±"],
    "Sweden": ["Sweden", "SE", "ğŸ‡¸ğŸ‡ª"],
    "Switzerland": ["Switzerland", "CH", "ğŸ‡¨ğŸ‡­"],
    "Italy": ["Italy", "IT", "ğŸ‡®ğŸ‡¹"],
    "Spain": ["Spain", "ES", "ğŸ‡ªğŸ‡¸"],
    "Estonia": ["Estonia", "EE", "ğŸ‡ªğŸ‡ª"],
    "UAE": ["UAE", "United Arab Emirates", "AE", "ğŸ‡¦ğŸ‡ª"],
    "Armenia": ["Armenia", "AM", "ğŸ‡¦ğŸ‡²"],
    "Argentina": ["Argentina", "AR", "ğŸ‡¦ğŸ‡·"],
    "Czechia": ["Czechia", "Czech", "CZ", "ğŸ‡¨ğŸ‡¿"],
    "Dominican": ["Dominican", "DO", "ğŸ‡©ğŸ‡´"],
    "Korea": ["Korea", "KR", "ğŸ‡°ğŸ‡·"],
}

def fetch_and_decode_content(url):
    """Ù…Ø­ØªÙˆØ§ÛŒ ÛŒÚ© URL Ø±Ø§ Ø¯Ø±ÛŒØ§ÙØª Ú©Ø±Ø¯Ù‡ Ùˆ Ø§Ú¯Ø± Ø¨Ø§ Base64 Ú©Ø¯ Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯ØŒ Ø¢Ù† Ø±Ø§ Ø¯ÛŒÚ©ÙˆØ¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    try:
        response = requests.get(url, timeout=20)
        response.raise_for_status()
        content = response.text
        try:
            decoded_content = base64.b64decode(content.strip()).decode('utf-8')
            return decoded_content.strip().split('\n')
        except Exception:
            return content.strip().split('\n')
    except requests.exceptions.RequestException as e:
        print(f"Error fetching from {url}: {e}")
        return []

def get_remark_from_config(config):
    """Ù†Ø§Ù… Ú©Ø§Ù†ÙÛŒÚ¯ (remark/ps) Ø±Ø§ Ø§Ø² Ø§Ù†ÙˆØ§Ø¹ Ú©Ø§Ù†ÙÛŒÚ¯ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    remark = ''
    try:
        if '#' in config:
            remark += " " + unquote(config.split('#', 1)[-1])
        
        if config.startswith('vmess://'):
            b64_part = config[8:]
            b64_part += '=' * (-len(b64_part) % 4)
            decoded_part = base64.b64decode(b64_part).decode('utf-8')
            vmess_data = json.loads(decoded_part)
            remark += " " + vmess_data.get('ps', '')
    except Exception:
        pass
    return remark.strip()

def find_country(remark):
    """Ú©Ø´ÙˆØ± Ø±Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§ÙˆÙ„ÙˆÛŒØª (Ø§ÛŒÙ…ÙˆØ¬ÛŒ > Ú©Ø¯ > Ù†Ø§Ù…) Ø¯Ø± Ù…ØªÙ† Ù¾ÛŒØ¯Ø§ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    for country_name, aliases in COUNTRY_ALIASES.items():
        for alias in aliases:
            # Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§ Ø§ÛŒÙ…ÙˆØ¬ÛŒâ€ŒÙ‡Ø§
            if not alias.isalpha() and len(alias) > 1:
                if alias in remark:
                    return country_name
    
    # Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ Ú©Ø¯Ù‡Ø§ÛŒ Ø¯Ùˆ Ø­Ø±ÙÛŒ
    tokens = set(re.split(r'[\s|\(\)\[\]\-_,]+', remark.upper()))
    for country_name, aliases in COUNTRY_ALIASES.items():
        for alias in aliases:
            if len(alias) == 2 and alias.isalpha() and alias.upper() in tokens:
                return country_name

    # Ø¬Ø³ØªØ¬Ùˆ Ø¨Ø±Ø§ÛŒ Ù†Ø§Ù… Ú©Ø§Ù…Ù„ Ú©Ø´ÙˆØ±
    for country_name, aliases in COUNTRY_ALIASES.items():
        for alias in aliases:
            if len(alias) > 2 and alias.isalpha():
                pattern = r'(?<![a-zA-Z0-9])' + re.escape(alias) + r'(?![a-zA-Z0-9])'
                if re.search(pattern, remark, re.IGNORECASE):
                    return country_name
    return None

def get_config_identifier(config):
    """ÛŒÚ© Ø´Ù†Ø§Ø³Ù‡ Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯ (Ø§Ø«Ø± Ø§Ù†Ú¯Ø´Øª) Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©Ø§Ù†ÙÛŒÚ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§ØµÙ„ÛŒ Ø³Ø±ÙˆØ± Ø§ÛŒØ¬Ø§Ø¯ Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    try:
        if config.startswith('vmess://'):
            b64_part = config.split('://')[1]
            if '#' in b64_part:
                b64_part = b64_part.split('#')[0]
            
            b64_part += '=' * (-len(b64_part) % 4)
            decoded_part = base64.b64decode(b64_part).decode('utf-8')
            vmess_data = json.loads(decoded_part)
            # Ø´Ù†Ø§Ø³Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§ØµÙ„ÛŒ Ø³Ø±ÙˆØ± Ø³Ø§Ø®ØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ùˆ 'ps' (Ù†Ø§Ù…) Ù†Ø§Ø¯ÛŒØ¯Ù‡ Ú¯Ø±ÙØªÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
            identifier_tuple = (
                vmess_data.get('add', ''),
                str(vmess_data.get('port', '')),
                vmess_data.get('id', ''),
                vmess_data.get('net', ''),
                vmess_data.get('type', ''),
                vmess_data.get('path', ''),
                vmess_data.get('host', '')
            )
            return f"vmess://{str(identifier_tuple)}"

        # --- Ù…Ù†Ø·Ù‚ Ø¬Ø¯ÛŒØ¯ Ùˆ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø¨Ø±Ø§ÛŒ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± URL ---
        config_no_fragment = config.split('#', 1)[0]
        parsed_url = urlparse(config_no_fragment)
        
        protocol = parsed_url.scheme
        hostname = parsed_url.hostname
        port = parsed_url.port
        path = parsed_url.path

        # Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ú©ÙˆØ¦Ø±ÛŒ Ø±Ø§ Ù…Ø±ØªØ¨ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… ØªØ§ ØªØ±ØªÛŒØ¨ Ø¢Ù†â€ŒÙ‡Ø§ Ø¯Ø± Ø´Ù†Ø§Ø³Ù‡ ØªØ£Ø«ÛŒØ±ÛŒ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
        query_params = parse_qs(parsed_url.query)
        sorted_params = []
        for key in sorted(query_params.keys()):
            sorted_values = sorted(query_params[key])
            sorted_params.append(f"{key}={'&'.join(sorted_values)}")
        
        # Ø´Ù†Ø§Ø³Ù‡ Ø±Ø§ Ø§Ø² Ø§Ø¬Ø²Ø§ÛŒ Ø§ØµÙ„ÛŒ Ø³Ø±ÙˆØ± Ù…ÛŒâ€ŒØ³Ø§Ø²ÛŒÙ…
        identifier_parts = [
            protocol,
            f"{hostname}:{port}",
            path,
        ] + sorted_params

        return "||".join(filter(None, identifier_parts))

    except Exception:
        # Ø¯Ø± ØµÙˆØ±Øª Ø¨Ø±ÙˆØ² Ù‡Ø±Ú¯ÙˆÙ†Ù‡ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø§Ø±Ø³ Ú©Ø±Ø¯Ù†ØŒ Ø§Ø² Ø±ÙˆØ´ Ø³Ø§Ø¯Ù‡â€ŒØªØ± Ù‚Ø¨Ù„ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯
        return config.split('#', 1)[0]

def remove_duplicates(configs):
    """Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ Ø±Ø§ Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø´Ù†Ø§Ø³Ù‡ Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯ Ø­Ø°Ù Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    seen_identifiers = set()
    unique_list = []
    for config in configs:
        identifier = get_config_identifier(config)
        if identifier not in seen_identifiers:
            seen_identifiers.add(identifier)
            unique_list.append(config)
    return unique_list

def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ú©Ù‡ ØªÙ…Ø§Ù… Ù…Ø±Ø§Ø­Ù„ Ø±Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ù…ÛŒâ€ŒÚ©Ù†Ø¯."""
    urls_str = os.environ.get('CONFIG_URLS')
    if not urls_str:
        print("CONFIG_URLS secret not found or is empty.")
        return

    urls = urls_str.strip().split('\n')
    all_configs = []

    print(f"Processing {len(urls)} URLs...")
    for url in urls:
        if url.strip():
            print(f"Fetching from: {url.strip()}")
            configs = fetch_and_decode_content(url.strip())
            if configs:
                all_configs.extend(configs)

    valid_protocols = ('vless://', 'vmess://', 'ss://', 'ssr://', 'trojan://', 'tuic://', 'hysteria://', 'hysteria2://')
    initial_valid_configs = [c.strip() for c in all_configs if c and c.strip().startswith(valid_protocols)]
    
    unique_configs = remove_duplicates(initial_valid_configs)
    
    print(f"\nFound {len(unique_configs)} unique configs. Now sorting...")

    by_protocol = defaultdict(list)
    by_country = defaultdict(list)

    for config in unique_configs:
        proto = config.split('://')[0]
        by_protocol[proto.upper()].append(config)

        remark = get_remark_from_config(config)
        country = find_country(remark)
        
        if country:
            by_country[country].append(config)
        else:
            by_country["Unknown"].append(config)
            
    # Ø­Ø°Ù Ùˆ Ø§ÛŒØ¬Ø§Ø¯ Ù…Ø¬Ø¯Ø¯ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§
    if os.path.exists('sub'):
        shutil.rmtree('sub')
        
    os.makedirs('sub/protocol', exist_ok=True)
    os.makedirs('sub/country', exist_ok=True)
    os.makedirs('sub/split', exist_ok=True) # --- Ù¾ÙˆØ´Ù‡ Ø¬Ø¯ÛŒØ¯ Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ ØªÙ‚Ø³ÛŒÙ…â€ŒØ´Ø¯Ù‡

    # Ù†ÙˆØ´ØªÙ† Ù‡Ù…Ù‡ Ú©Ø§Ù†ÙÛŒÚ¯â€ŒÙ‡Ø§ÛŒ Ù…Ù†Ø­ØµØ± Ø¨Ù‡ ÙØ±Ø¯ Ø¯Ø± ÛŒÚ© ÙØ§ÛŒÙ„
    with open('v2ray_configs.txt', 'w', encoding='utf-8') as f:
        f.write('\n'.join(unique_configs))
    
    # --- Ø¨Ø®Ø´ Ø¬Ø¯ÛŒØ¯: ØªÙ‚Ø³ÛŒÙ… ÙØ§ÛŒÙ„ Ø§ØµÙ„ÛŒ Ø¨Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©â€ŒØªØ± ---
    chunk_size = 100
    for i in range(0, len(unique_configs), chunk_size):
        chunk = unique_configs[i:i + chunk_size]
        file_path = f'sub/split/v2ray_configs_{i // chunk_size + 1}.txt'
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(chunk))
    print(f"âœ… Main config file split into smaller files in 'sub/split/' directory.")
    # --- Ù¾Ø§ÛŒØ§Ù† Ø¨Ø®Ø´ Ø¬Ø¯ÛŒØ¯ ---

    # Ù†ÙˆØ´ØªÙ† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù¾Ø±ÙˆØªÚ©Ù„
    for proto, configs in by_protocol.items():
        with open(f'sub/protocol/{proto}.txt', 'w', encoding='utf-8') as f:
            f.write('\n'.join(configs))
    
    # Ù†ÙˆØ´ØªÙ† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©Ø´ÙˆØ±
    for country, configs in by_country.items():
        if configs:
            with open(f'sub/country/{country}.txt', 'w', encoding='utf-8') as f:
                f.write('\n'.join(configs))

    print("\nâœ… Success! All configs have been sorted accurately and saved.")

if __name__ == "__main__":
    main()
